{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types\n",
    "# from pyspark import SparkConf\n",
    "from pyspark import pandas\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, FloatType\n",
    "# from pyspark.sql.functions import pandas_udf\n",
    "import re\n",
    "from pyspark.sql import functions\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/28 12:02:10 WARN Utils: Your hostname, babydata resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "22/12/28 12:02:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/28 12:02:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# _sconf = SparkConf().setAppName(\"practice\").setMaster(\"locals\")\n",
    "_context = SparkContext(\"local\", \"practice\")\n",
    "spark = SparkSession(_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/Merging.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = StructType([\\\n",
    "            StructField(\"Flight_date\", StringType(), True), \\\n",
    "            StructField(\"From\", StringType(), True), \\\n",
    "            StructField(\"To\", StringType(), True), \\\n",
    "            StructField(\"Duration\", StringType(), True), \\\n",
    "            StructField(\"STD\", StringType(), True), \\\n",
    "            StructField(\"ATD\", StringType(), True), \\\n",
    "            StructField(\"STA\", StringType(), True), \\\n",
    "            StructField(\"ATA\", StringType(), True),\\\n",
    "            StructField(\"Signal\", StringType(), True),\\\n",
    "            StructField(\"Temp\", IntegerType(), True),\\\n",
    "            StructField(\"Weather\", StringType(), True),\\\n",
    "            StructField(\"Wind\", IntegerType(), True),\\\n",
    "            StructField(\"Direction\", StringType(), True),\\\n",
    "            StructField(\"Humidity\", IntegerType(), True),\\\n",
    "            StructField(\"Barometer\", IntegerType(), True),\\\n",
    "            StructField(\"Visibility\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = spark.read.option(\"delimiter\", \",\").option(\"header\", True).schema(_schema).csv(path_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"red\">Tien xu ly du lieu</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i>XU LY GIA TRI NULL\\NONE</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [Flight_date#0,From#1,To#2,Duration#3,STD#4,ATD#5,STA#6,ATA#7,Signal#8,Temp#9,Weather#10,Wind#11,Direction#12,Humidity#13,Barometer#14,Visibility#15] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/hong_hai/BigData/Code/Final_Project/data/Merging.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Flight_date:string,From:string,To:string,Duration:string,STD:string,ATD:string,STA:string,...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_data.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Flight_date: string (nullable = true)\n",
      " |-- From: string (nullable = true)\n",
      " |-- To: string (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- STD: string (nullable = true)\n",
      " |-- ATD: string (nullable = true)\n",
      " |-- STA: string (nullable = true)\n",
      " |-- ATA: string (nullable = true)\n",
      " |-- Signal: string (nullable = true)\n",
      " |-- Temp: integer (nullable = true)\n",
      " |-- Weather: string (nullable = true)\n",
      " |-- Wind: integer (nullable = true)\n",
      " |-- Direction: string (nullable = true)\n",
      " |-- Humidity: integer (nullable = true)\n",
      " |-- Barometer: integer (nullable = true)\n",
      " |-- Visibility: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+----------+\n",
      "|Flight_date|From| To|Duration|STD|ATD|STA|ATA|Signal|Temp|Weather|Wind|Direction|Humidity|Barometer|Visibility|\n",
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+----------+\n",
      "|          0|   0|  0|       0|  0|  0|  0|  0|     0|8317|   8322|9226|     8317|    8326|     8378|     78156|\n",
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_data.select([functions.count( functions.when( functions.isnan(column) | functions.col(column).isNull(), column)).alias(column) for column in _data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_listColNull = ['Temp', 'Weather', 'Wind', 'Direction', 'Humidity', 'Barometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clear_data_1 = _data.where(_data['Temp'].isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+----------+\n",
      "|Flight_date|From|To |Duration|STD|ATD|STA|ATA|Signal|Temp|Weather|Wind|Direction|Humidity|Barometer|Visibility|\n",
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+----------+\n",
      "|0          |0   |0  |0       |0  |0  |0  |0  |0     |0   |5      |909 |0        |9       |61       |69839     |\n",
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Clear_data_1.select([functions.count( functions.when( functions.isnan(column) | functions.col(column).isNull(), column)).alias(column) for column in Clear_data_1.columns]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100521"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clear_data_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clear_data_2 = Clear_data_1.drop(\"Visibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flight_date',\n",
       " 'From',\n",
       " 'To',\n",
       " 'Duration',\n",
       " 'STD',\n",
       " 'ATD',\n",
       " 'STA',\n",
       " 'ATA',\n",
       " 'Signal',\n",
       " 'Temp',\n",
       " 'Weather',\n",
       " 'Wind',\n",
       " 'Direction',\n",
       " 'Humidity',\n",
       " 'Barometer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clear_data_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Wind|num_row|\n",
      "+----+-------+\n",
      "|7   |13816  |\n",
      "|6   |13548  |\n",
      "|9   |13101  |\n",
      "|11  |11132  |\n",
      "|4   |10833  |\n",
      "|13  |9459   |\n",
      "|15  |7467   |\n",
      "|17  |5857   |\n",
      "|2   |5297   |\n",
      "|19  |3908   |\n",
      "|20  |2099   |\n",
      "|22  |1246   |\n",
      "|24  |635    |\n",
      "|26  |443    |\n",
      "|28  |310    |\n",
      "|30  |183    |\n",
      "|32  |96     |\n",
      "|33  |79     |\n",
      "|35  |33     |\n",
      "|41  |22     |\n",
      "|39  |18     |\n",
      "|37  |12     |\n",
      "|43  |11     |\n",
      "|46  |4      |\n",
      "|5   |1      |\n",
      "|21  |1      |\n",
      "|50  |1      |\n",
      "|null|0      |\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Clear_data_2.groupBy(\"Wind\").agg(functions.count(\"Wind\").alias(\"num_row\")).sort(functions.col(\"num_row\").desc()).show(Clear_data_2.count(),truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_data_1 = Clear_data_2.fillna(13816, \"Wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|Humidity|num_row|\n",
      "+--------+-------+\n",
      "|89      |9105   |\n",
      "|94      |8861   |\n",
      "|79      |8734   |\n",
      "|84      |7976   |\n",
      "|70      |6171   |\n",
      "|66      |4752   |\n",
      "|59      |4595   |\n",
      "|74      |4098   |\n",
      "|75      |3879   |\n",
      "|49      |3514   |\n",
      "|100     |3500   |\n",
      "|62      |3283   |\n",
      "|63      |3149   |\n",
      "|55      |3124   |\n",
      "|52      |2861   |\n",
      "|67      |2505   |\n",
      "|56      |2222   |\n",
      "|46      |2007   |\n",
      "|44      |1571   |\n",
      "|41      |1230   |\n",
      "|53      |1166   |\n",
      "|47      |1068   |\n",
      "|71      |1065   |\n",
      "|58      |1032   |\n",
      "|83      |1027   |\n",
      "|43      |741    |\n",
      "|36      |738    |\n",
      "|51      |669    |\n",
      "|38      |592    |\n",
      "|39      |529    |\n",
      "|34      |463    |\n",
      "|78      |444    |\n",
      "|65      |439    |\n",
      "|50      |425    |\n",
      "|48      |423    |\n",
      "|69      |381    |\n",
      "|32      |303    |\n",
      "|61      |255    |\n",
      "|54      |229    |\n",
      "|40      |224    |\n",
      "|30      |156    |\n",
      "|45      |143    |\n",
      "|73      |109    |\n",
      "|37      |107    |\n",
      "|42      |103    |\n",
      "|88      |101    |\n",
      "|28      |93     |\n",
      "|57      |78     |\n",
      "|33      |74     |\n",
      "|35      |58     |\n",
      "|26      |35     |\n",
      "|31      |24     |\n",
      "|23      |14     |\n",
      "|25      |12     |\n",
      "|24      |11     |\n",
      "|29      |11     |\n",
      "|21      |7      |\n",
      "|12      |6      |\n",
      "|22      |4      |\n",
      "|19      |4      |\n",
      "|64      |4      |\n",
      "|60      |4      |\n",
      "|16      |3      |\n",
      "|27      |1      |\n",
      "|null    |0      |\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_data_1.groupBy(\"Humidity\").agg(functions.count(\"Humidity\").alias(\"num_row\")).sort(functions.col(\"num_row\").desc()).show(fill_data_1.count(),truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_data_2 = fill_data_1.fillna(9105, \"Humidity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|Barometer|num_row|\n",
      "+---------+-------+\n",
      "|1008     |15193  |\n",
      "|1009     |14569  |\n",
      "|1010     |12998  |\n",
      "|1007     |12504  |\n",
      "|1011     |10204  |\n",
      "|1006     |8883   |\n",
      "|1012     |7429   |\n",
      "|1005     |6391   |\n",
      "|1013     |4322   |\n",
      "|1004     |3022   |\n",
      "|1014     |2277   |\n",
      "|1003     |1201   |\n",
      "|1015     |830    |\n",
      "|1002     |294    |\n",
      "|1016     |209    |\n",
      "|1001     |96     |\n",
      "|1017     |30     |\n",
      "|1000     |8      |\n",
      "|null     |0      |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_data_2.groupBy(\"Barometer\").agg(functions.count(\"Barometer\").alias(\"num_row\")).sort(functions.col(\"num_row\").desc()).show(fill_data_2.count(),truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_data_3 = fill_data_2.fillna(15193,\"Barometer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+\n",
      "|Flight_date|From|To |Duration|STD|ATD|STA|ATA|Signal|Temp|Weather|Wind|Direction|Humidity|Barometer|\n",
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+\n",
      "|0          |0   |0  |0       |0  |0  |0  |0  |0     |0   |5      |0   |0        |0       |0        |\n",
      "+-----------+----+---+--------+---+---+---+---+------+----+-------+----+---------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fill_data_3.select([functions.count( functions.when( functions.isnan(column) | functions.col(column).isNull(), column)).alias(column) for column in fill_data_3.columns]).show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transformation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_signal(signal: str) -> int:\n",
    "    if signal == 'red':\n",
    "        return 1\n",
    "    elif signal == 'green':\n",
    "        return 2\n",
    "    else: return 3\n",
    "udf_signal = functions.udf(lambda row: transform_signal(row), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data_1 = fill_data_3.withColumn(\"num_signal\", udf_signal(functions.col(\"Signal\"))).drop(\"Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_direc(dir: str):\n",
    "    pattern = r'[0-9]+'\n",
    "    result = re.findall(pattern, dir)\n",
    "    return IntegerType().toInternal(int(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_direct = functions.udf(transform_direc, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+--------+-----+-----+-----+-----+----+--------------------+----+--------+---------+----------+----------+\n",
      "|Flight_date|                From|            To|Duration|  STD|  ATD|  STA|  ATA|Temp|             Weather|Wind|Humidity|Barometer|num_signal|num_direct|\n",
      "+-----------+--------------------+--------------+--------+-----+-----+-----+-----+----+--------------------+----+--------+---------+----------+----------+\n",
      "| 13/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:15|15:30|15:46|17:05|17:01|  32|   Scattered clouds.|  13|      67|     1007|         2|       200|\n",
      "| 12/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:09|18:00|18:17|19:20|19:26|  26|Thundershowers. P...|   6|      89|     1008|         2|         0|\n",
      "| 11/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:13|15:30|16:23|17:05|17:36|  29|   Scattered clouds.|   6|      79|     1006|         3|         0|\n",
      "| 09/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:14|15:30|17:07|17:05|18:21|  33|   Scattered clouds.|   6|      59|     1007|         1|         0|\n",
      "| 07/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:12|15:30|15:57|17:05|17:09|  27|Light rain. Broke...|  17|      89|     1007|         2|       260|\n",
      "| 06/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:14|15:30|15:42|17:05|16:56|  32|   Scattered clouds.|  19|      59|     1006|         2|       280|\n",
      "| 04/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:13|15:30|17:27|17:05|18:40|  30|   Scattered clouds.|  17|      66|     1006|         1|       270|\n",
      "| 03/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:22|15:30|16:10|17:05|17:32|  33|   Scattered clouds.|  11|      59|     1004|         3|       270|\n",
      "| 02/09/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:20|15:30|15:56|17:05|17:16|  28|Sprinkles. Scatte...|  11|      89|     1005|         2|       280|\n",
      "| 31/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:07|15:30|16:41|17:05|17:48|  32|   Scattered clouds.|   6|      63|     1004|         3|         0|\n",
      "| 29/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:14|15:30|16:36|17:05|17:51|  33|   Scattered clouds.|  19|      63|     1006|         1|       150|\n",
      "| 28/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:15|15:30|16:11|17:05|17:27|  32|Sprinkles. Scatte...|   4|      63|     1004|         3|         0|\n",
      "| 26/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:08|15:30|16:27|17:05|17:35|  24|Light rain. Broke...|  19|      94|     1009|         3|       250|\n",
      "| 25/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:10|15:30|16:01|17:05|17:11|  28|Sprinkles. Scatte...|  17|      79|     1006|         2|       220|\n",
      "| 24/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:12|15:30|17:46|17:05|18:58|  33|   Scattered clouds.|  11|      59|     1003|         1|       310|\n",
      "| 23/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:13|15:30|15:48|17:05|17:01|  33|   Scattered clouds.|  13|      59|     1004|         2|       290|\n",
      "| 22/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:18|15:30|18:37|17:05|19:55|  34|Scattered showers...|  17|      53|     1004|         1|       280|\n",
      "| 21/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:10|15:30|16:16|17:05|17:25|  29|   Scattered clouds.|  19|      70|     1005|         3|       240|\n",
      "| 20/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:11|15:30|16:32|17:05|17:43|  29|      Broken clouds.|  20|      79|     1004|         3|       250|\n",
      "| 19/08/2022|Ho Chi Minh City ...|Dong Hoi (VDH)|   01:38|15:30|16:18|17:05|17:56|  30|Sprinkles. Scatte...|  26|      70|     1004|         1|       250|\n",
      "+-----------+--------------------+--------------+--------+-----+-----+-----+-----+----+--------------------+----+--------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trans_data_2 = trans_data_1.withColumn(\"num_direct\", udf_direct(functions.col(\"Direction\"))).drop(\"Direction\")\n",
    "trans_data_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|To                    |\n",
      "+----------------------+\n",
      "|Haiphong (HPH)        |\n",
      "|Ho Chi Minh City (SGN)|\n",
      "|Quang Ninh (VDO)      |\n",
      "|Pleiku (PXU)          |\n",
      "|Can Tho (VCA)         |\n",
      "|Ca Mau (CAH)          |\n",
      "|Hanoi (HAN)           |\n",
      "|Con Dao (VCS)         |\n",
      "|Qui Nhon (UIH)        |\n",
      "|Da Nang (DAD)         |\n",
      "|Dong Hoi (VDH)        |\n",
      "|Nha Trang (CXR)       |\n",
      "|Buon Ma Thuot (BMV)   |\n",
      "|Tuy Hoa (TBB)         |\n",
      "|Vinh (VII)            |\n",
      "|Phu Quoc (PQC)        |\n",
      "|Hue (HUI)             |\n",
      "|Sao Vang (THD)        |\n",
      "|Chu Lai (VCL)         |\n",
      "|Da Lat (DLI)          |\n",
      "|Dien Bien Phu (DIN)   |\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_data_2.select(functions.col(\"To\")).distinct().show(25, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = {'Haiphong (HPH)': 1, 'Quang Ninh (VDO)': 2, 'Pleiku (PXU)': 3, 'Can Tho (VCA)': 4,\\\n",
    "            'Ca Mau (CAH)': 5, 'Hanoi (HAN)': 6, 'Con Dao (VCS)': 7, 'Qui Nhon (UIH)': 8, 'Da Nang (DAD)': 9,\\\n",
    "            'Dong Hoi (VDH)': 10, 'Nha Trang (CXR)': 11, 'Buon Ma Thuot (BMV)': 12, 'Tuy Hoa (TBB)': 13,\\\n",
    "            'Vinh (VII)': 14, 'Phu Quoc (PQC)': 15, 'Hue (HUI)': 16, 'Sao Vang (THD)': 17, 'Chu Lai (VCL)': 18, 'Da Lat (DLI)': 19, 'Dien Bien Phu (DIN)': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data_2 = trans_data_2.filter(functions.col(\"To\") != \"Ho Chi Minh City (SGN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_city(city:str) -> int:\n",
    "    return IntegerType().toInternal(city_list[city])\n",
    "udf_city = functions.udf(transform_city, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----+-----+-----+-----+----+--------------------+----+--------+---------+----------+----------+--------+\n",
      "|Flight_date|Duration|  STD|  ATD|  STA|  ATA|Temp|             Weather|Wind|Humidity|Barometer|num_signal|num_direct|num_city|\n",
      "+-----------+--------+-----+-----+-----+-----+----+--------------------+----+--------+---------+----------+----------+--------+\n",
      "| 13/09/2022|   01:15|15:30|15:46|17:05|17:01|  32|   Scattered clouds.|  13|      67|     1007|         2|       200|      10|\n",
      "| 12/09/2022|   01:09|18:00|18:17|19:20|19:26|  26|Thundershowers. P...|   6|      89|     1008|         2|         0|      10|\n",
      "| 11/09/2022|   01:13|15:30|16:23|17:05|17:36|  29|   Scattered clouds.|   6|      79|     1006|         3|         0|      10|\n",
      "| 09/09/2022|   01:14|15:30|17:07|17:05|18:21|  33|   Scattered clouds.|   6|      59|     1007|         1|         0|      10|\n",
      "| 07/09/2022|   01:12|15:30|15:57|17:05|17:09|  27|Light rain. Broke...|  17|      89|     1007|         2|       260|      10|\n",
      "| 06/09/2022|   01:14|15:30|15:42|17:05|16:56|  32|   Scattered clouds.|  19|      59|     1006|         2|       280|      10|\n",
      "| 04/09/2022|   01:13|15:30|17:27|17:05|18:40|  30|   Scattered clouds.|  17|      66|     1006|         1|       270|      10|\n",
      "| 03/09/2022|   01:22|15:30|16:10|17:05|17:32|  33|   Scattered clouds.|  11|      59|     1004|         3|       270|      10|\n",
      "| 02/09/2022|   01:20|15:30|15:56|17:05|17:16|  28|Sprinkles. Scatte...|  11|      89|     1005|         2|       280|      10|\n",
      "| 31/08/2022|   01:07|15:30|16:41|17:05|17:48|  32|   Scattered clouds.|   6|      63|     1004|         3|         0|      10|\n",
      "| 29/08/2022|   01:14|15:30|16:36|17:05|17:51|  33|   Scattered clouds.|  19|      63|     1006|         1|       150|      10|\n",
      "| 28/08/2022|   01:15|15:30|16:11|17:05|17:27|  32|Sprinkles. Scatte...|   4|      63|     1004|         3|         0|      10|\n",
      "| 26/08/2022|   01:08|15:30|16:27|17:05|17:35|  24|Light rain. Broke...|  19|      94|     1009|         3|       250|      10|\n",
      "| 25/08/2022|   01:10|15:30|16:01|17:05|17:11|  28|Sprinkles. Scatte...|  17|      79|     1006|         2|       220|      10|\n",
      "| 24/08/2022|   01:12|15:30|17:46|17:05|18:58|  33|   Scattered clouds.|  11|      59|     1003|         1|       310|      10|\n",
      "| 23/08/2022|   01:13|15:30|15:48|17:05|17:01|  33|   Scattered clouds.|  13|      59|     1004|         2|       290|      10|\n",
      "| 22/08/2022|   01:18|15:30|18:37|17:05|19:55|  34|Scattered showers...|  17|      53|     1004|         1|       280|      10|\n",
      "| 21/08/2022|   01:10|15:30|16:16|17:05|17:25|  29|   Scattered clouds.|  19|      70|     1005|         3|       240|      10|\n",
      "| 20/08/2022|   01:11|15:30|16:32|17:05|17:43|  29|      Broken clouds.|  20|      79|     1004|         3|       250|      10|\n",
      "| 19/08/2022|   01:38|15:30|16:18|17:05|17:56|  30|Sprinkles. Scatte...|  26|      70|     1004|         1|       250|      10|\n",
      "+-----------+--------+-----+-----+-----+-----+----+--------------------+----+--------+---------+----------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_data_3 = trans_data_2.withColumn(\"num_city\", udf_city(functions.col(\"To\"))).drop(\"To\").drop(\"From\")\n",
    "trans_data_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_time(_date: str, _time: str) -> int:\n",
    "    _datetime = _date + \" \" +_time\n",
    "    obj_datetime = datetime.strptime(_datetime, \"%d/%m/%Y %H:%M\")\n",
    "    result = int(time.mktime(obj_datetime.timetuple()))\n",
    "    return result\n",
    "udf_time = functions.udf(transform_time, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+--------------------+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+\n",
      "|Duration|Temp|             Weather|Wind|Humidity|Barometer|num_signal|num_direct|num_city|   tmp_STD|   tmp_ATD|   tmp_STA|   tmp_ATA|\n",
      "+--------+----+--------------------+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+\n",
      "|   01:15|  32|   Scattered clouds.|  13|      67|     1007|         2|       200|      10|1663057800|1663058760|1663063500|1663063260|\n",
      "|   01:09|  26|Thundershowers. P...|   6|      89|     1008|         2|         0|      10|1662980400|1662981420|1662985200|1662985560|\n",
      "|   01:13|  29|   Scattered clouds.|   6|      79|     1006|         3|         0|      10|1662885000|1662888180|1662890700|1662892560|\n",
      "|   01:14|  33|   Scattered clouds.|   6|      59|     1007|         1|         0|      10|1662712200|1662718020|1662717900|1662722460|\n",
      "|   01:12|  27|Light rain. Broke...|  17|      89|     1007|         2|       260|      10|1662539400|1662541020|1662545100|1662545340|\n",
      "|   01:14|  32|   Scattered clouds.|  19|      59|     1006|         2|       280|      10|1662453000|1662453720|1662458700|1662458160|\n",
      "|   01:13|  30|   Scattered clouds.|  17|      66|     1006|         1|       270|      10|1662280200|1662287220|1662285900|1662291600|\n",
      "|   01:22|  33|   Scattered clouds.|  11|      59|     1004|         3|       270|      10|1662193800|1662196200|1662199500|1662201120|\n",
      "|   01:20|  28|Sprinkles. Scatte...|  11|      89|     1005|         2|       280|      10|1662107400|1662108960|1662113100|1662113760|\n",
      "|   01:07|  32|   Scattered clouds.|   6|      63|     1004|         3|         0|      10|1661934600|1661938860|1661940300|1661942880|\n",
      "|   01:14|  33|   Scattered clouds.|  19|      63|     1006|         1|       150|      10|1661761800|1661765760|1661767500|1661770260|\n",
      "|   01:15|  32|Sprinkles. Scatte...|   4|      63|     1004|         3|         0|      10|1661675400|1661677860|1661681100|1661682420|\n",
      "|   01:08|  24|Light rain. Broke...|  19|      94|     1009|         3|       250|      10|1661502600|1661506020|1661508300|1661510100|\n",
      "|   01:10|  28|Sprinkles. Scatte...|  17|      79|     1006|         2|       220|      10|1661416200|1661418060|1661421900|1661422260|\n",
      "|   01:12|  33|   Scattered clouds.|  11|      59|     1003|         1|       310|      10|1661329800|1661337960|1661335500|1661342280|\n",
      "|   01:13|  33|   Scattered clouds.|  13|      59|     1004|         2|       290|      10|1661243400|1661244480|1661249100|1661248860|\n",
      "|   01:18|  34|Scattered showers...|  17|      53|     1004|         1|       280|      10|1661157000|1661168220|1661162700|1661172900|\n",
      "|   01:10|  29|   Scattered clouds.|  19|      70|     1005|         3|       240|      10|1661070600|1661073360|1661076300|1661077500|\n",
      "|   01:11|  29|      Broken clouds.|  20|      79|     1004|         3|       250|      10|1660984200|1660987920|1660989900|1660992180|\n",
      "|   01:38|  30|Sprinkles. Scatte...|  26|      70|     1004|         1|       250|      10|1660897800|1660900680|1660903500|1660906560|\n",
      "+--------+----+--------------------+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_data_4 = trans_data_3.withColumn(\"tmp_STD\", udf_time(functions.col(\"Flight_date\"), functions.col(\"STD\")))\\\n",
    "            .withColumn(\"tmp_ATD\", udf_time(functions.col(\"Flight_date\"), functions.col(\"ATD\")))\\\n",
    "            .withColumn(\"tmp_STA\", udf_time(functions.col(\"Flight_date\"), functions.col(\"STA\")))\\\n",
    "            .withColumn(\"tmp_ATA\", udf_time(functions.col(\"Flight_date\"), functions.col(\"ATA\")))\\\n",
    "            .drop(\"STD\").drop(\"ATD\").drop(\"STA\").drop(\"ATA\").drop(\"Flight_date\")\n",
    "trans_data_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_duration(_time: str) -> int:\n",
    "    _hour = int(_time[:2])\n",
    "    _minutes = int(_time[3:])\n",
    "    return IntegerType().toInternal(_hour * 60 + _minutes)\n",
    "udf_duration = functions.udf(transform_duration, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data_5 = trans_data_4.withColumn(\"num_duration\", udf_duration(functions.col(\"Duration\"))).drop(\"Duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+------------+\n",
      "|Temp|             Weather|Wind|Humidity|Barometer|num_signal|num_direct|num_city|   tmp_STD|   tmp_ATD|   tmp_STA|   tmp_ATA|num_duration|\n",
      "+----+--------------------+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+------------+\n",
      "|  32|   Scattered clouds.|  13|      67|     1007|         2|       200|      10|1663057800|1663058760|1663063500|1663063260|          75|\n",
      "|  26|Thundershowers. P...|   6|      89|     1008|         2|         0|      10|1662980400|1662981420|1662985200|1662985560|          69|\n",
      "|  29|   Scattered clouds.|   6|      79|     1006|         3|         0|      10|1662885000|1662888180|1662890700|1662892560|          73|\n",
      "|  33|   Scattered clouds.|   6|      59|     1007|         1|         0|      10|1662712200|1662718020|1662717900|1662722460|          74|\n",
      "|  27|Light rain. Broke...|  17|      89|     1007|         2|       260|      10|1662539400|1662541020|1662545100|1662545340|          72|\n",
      "|  32|   Scattered clouds.|  19|      59|     1006|         2|       280|      10|1662453000|1662453720|1662458700|1662458160|          74|\n",
      "|  30|   Scattered clouds.|  17|      66|     1006|         1|       270|      10|1662280200|1662287220|1662285900|1662291600|          73|\n",
      "|  33|   Scattered clouds.|  11|      59|     1004|         3|       270|      10|1662193800|1662196200|1662199500|1662201120|          82|\n",
      "|  28|Sprinkles. Scatte...|  11|      89|     1005|         2|       280|      10|1662107400|1662108960|1662113100|1662113760|          80|\n",
      "|  32|   Scattered clouds.|   6|      63|     1004|         3|         0|      10|1661934600|1661938860|1661940300|1661942880|          67|\n",
      "|  33|   Scattered clouds.|  19|      63|     1006|         1|       150|      10|1661761800|1661765760|1661767500|1661770260|          74|\n",
      "|  32|Sprinkles. Scatte...|   4|      63|     1004|         3|         0|      10|1661675400|1661677860|1661681100|1661682420|          75|\n",
      "|  24|Light rain. Broke...|  19|      94|     1009|         3|       250|      10|1661502600|1661506020|1661508300|1661510100|          68|\n",
      "|  28|Sprinkles. Scatte...|  17|      79|     1006|         2|       220|      10|1661416200|1661418060|1661421900|1661422260|          70|\n",
      "|  33|   Scattered clouds.|  11|      59|     1003|         1|       310|      10|1661329800|1661337960|1661335500|1661342280|          72|\n",
      "|  33|   Scattered clouds.|  13|      59|     1004|         2|       290|      10|1661243400|1661244480|1661249100|1661248860|          73|\n",
      "|  34|Scattered showers...|  17|      53|     1004|         1|       280|      10|1661157000|1661168220|1661162700|1661172900|          78|\n",
      "|  29|   Scattered clouds.|  19|      70|     1005|         3|       240|      10|1661070600|1661073360|1661076300|1661077500|          70|\n",
      "|  29|      Broken clouds.|  20|      79|     1004|         3|       250|      10|1660984200|1660987920|1660989900|1660992180|          71|\n",
      "|  30|Sprinkles. Scatte...|  26|      70|     1004|         1|       250|      10|1660897800|1660900680|1660903500|1660906560|          98|\n",
      "+----+--------------------+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_data_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+-------+\n",
      "|Weather                                    |num_row|\n",
      "+-------------------------------------------+-------+\n",
      "|Scattered clouds.                          |33155  |\n",
      "|Passing clouds.                            |28019  |\n",
      "|Partly sunny.                              |20616  |\n",
      "|Broken clouds.                             |4621   |\n",
      "|Fog.                                       |2329   |\n",
      "|Partly cloudy.                             |1447   |\n",
      "|Sprinkles. Scattered clouds.               |1202   |\n",
      "|Thunderstorms. Scattered clouds.           |947    |\n",
      "|Clear.                                     |823    |\n",
      "|Light rain. Broken clouds.                 |773    |\n",
      "|Sunny.                                     |637    |\n",
      "|Sprinkles. Partly sunny.                   |614    |\n",
      "|Light rain. Partly cloudy.                 |577    |\n",
      "|More clouds than sun.                      |479    |\n",
      "|Thunderstorms. Broken clouds.              |456    |\n",
      "|Sprinkles. Broken clouds.                  |365    |\n",
      "|Mostly cloudy.                             |274    |\n",
      "|Scattered showers. Scattered clouds.       |230    |\n",
      "|Light rain. Scattered clouds.              |173    |\n",
      "|Thundershowers. Scattered clouds.          |169    |\n",
      "|Light rain. Passing clouds.                |162    |\n",
      "|Thunderstorms. Partly sunny.               |157    |\n",
      "|Thunderstorms. Passing clouds.             |155    |\n",
      "|Light rain. More clouds than sun.          |151    |\n",
      "|Sprinkles. Passing clouds.                 |138    |\n",
      "|Thunderstorms. Partly cloudy.              |138    |\n",
      "|Sprinkles. Partly cloudy.                  |125    |\n",
      "|Strong thunderstorms. Broken clouds.       |114    |\n",
      "|Rain showers. Broken clouds.               |114    |\n",
      "|Light rain. Partly sunny.                  |106    |\n",
      "|Rain showers. Scattered clouds.            |96     |\n",
      "|Warm.                                      |88     |\n",
      "|Lots of rain. Broken clouds.               |83     |\n",
      "|Scattered showers. Partly sunny.           |77     |\n",
      "|Strong thunderstorms. Scattered clouds.    |75     |\n",
      "|Rain. Fog.                                 |71     |\n",
      "|Overcast.                                  |66     |\n",
      "|Lots of rain. Scattered clouds.            |58     |\n",
      "|Rain showers. Partly sunny.                |56     |\n",
      "|Light rain. Mostly cloudy.                 |48     |\n",
      "|Thundershowers. Broken clouds.             |48     |\n",
      "|Light rain. Fog.                           |47     |\n",
      "|Thundershowers. Passing clouds.            |46     |\n",
      "|Haze.                                      |33     |\n",
      "|Scattered showers. Broken clouds.          |30     |\n",
      "|Thundershowers. Partly cloudy.             |28     |\n",
      "|Light rain. Overcast.                      |26     |\n",
      "|Cloudy.                                    |23     |\n",
      "|Thunderstorms. More clouds than sun.       |22     |\n",
      "|Strong thunderstorms. Partly cloudy.       |18     |\n",
      "|Strong thunderstorms. Partly sunny.        |17     |\n",
      "|Sprinkles. More clouds than sun.           |14     |\n",
      "|Strong thunderstorms. More clouds than sun.|13     |\n",
      "|Light rain. Cloudy.                        |12     |\n",
      "|Rain showers. Passing clouds.              |12     |\n",
      "|Rain showers. Partly cloudy.               |12     |\n",
      "|Heavy rain. Fog.                           |10     |\n",
      "|Rain. Broken clouds.                       |10     |\n",
      "|Lots of rain. Partly sunny.                |9      |\n",
      "|Lots of rain. Passing clouds.              |8      |\n",
      "|Light fog.                                 |6      |\n",
      "|Strong thunderstorms. Passing clouds.      |6      |\n",
      "|Hot.                                       |6      |\n",
      "|Thunderstorms. Fog.                        |6      |\n",
      "|Mild.                                      |6      |\n",
      "|Lots of rain. Partly cloudy.               |5      |\n",
      "|Rain showers. More clouds than sun.        |5      |\n",
      "|Sprinkles. Overcast.                       |5      |\n",
      "|Rain. More clouds than sun.                |5      |\n",
      "|Strong thunderstorms. Fog.                 |5      |\n",
      "|Rain showers. Cloudy.                      |5      |\n",
      "|Rain. Passing clouds.                      |5      |\n",
      "|Sprinkles. Mostly cloudy.                  |4      |\n",
      "|Strong thunderstorms. Cloudy.              |4      |\n",
      "|Scattered showers. Overcast.               |3      |\n",
      "|Rain. Partly cloudy.                       |3      |\n",
      "|Rain showers. Mostly cloudy.               |3      |\n",
      "|Thunderstorms. Mostly cloudy.              |2      |\n",
      "|Rain. Cloudy.                              |1      |\n",
      "|Light rain. Clear.                         |1      |\n",
      "|Sprinkles. Clear.                          |1      |\n",
      "|Rain showers. Overcast.                    |1      |\n",
      "|Lots of rain. Fog.                         |1      |\n",
      "|Sprinkles. Cloudy.                         |1      |\n",
      "|Scattered showers. Passing clouds.         |1      |\n",
      "|null                                       |0      |\n",
      "+-------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_data_5.groupBy(\"Weather\").agg(functions.count(\"Weather\").alias(\"num_row\")).sort(functions.col(\"num_row\").desc()).show(trans_data_5.count(),truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def split_weather_list(weather: str):\n",
    "    _list = []\n",
    "    for w in re.findall(r\"([a-zA-Z]+[ \\t]*[a-zA-Z]*).\", weather):\n",
    "        _list.append(w)\n",
    "    return ArrayType(StringType()).toInternal(_list)\n",
    "udf_createWList = functions.udf(split_weather_list, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data_6 = trans_data_5.fillna(\"Scattered clouds\", subset=\"Weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Weather|\n",
      "+--------------------+\n",
      "| Light rain. Cloudy.|\n",
      "|Strong thundersto...|\n",
      "|Thunderstorms. Sc...|\n",
      "|Thundershowers. P...|\n",
      "|Thunderstorms. Br...|\n",
      "|              Sunny.|\n",
      "|Rain showers. Pas...|\n",
      "|Strong thundersto...|\n",
      "|Lots of rain. Sca...|\n",
      "|Thunderstorms. Pa...|\n",
      "|Thundershowers. S...|\n",
      "|               Mild.|\n",
      "|Thunderstorms. Mo...|\n",
      "|Strong thundersto...|\n",
      "|Light rain. Scatt...|\n",
      "|Rain showers. Clo...|\n",
      "|       Rain. Cloudy.|\n",
      "|Light rain. Mostl...|\n",
      "|  Light rain. Clear.|\n",
      "|Sprinkles. Overcast.|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_data_6.select(\"Weather\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hong_hai/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3313: FutureWarning: DataFrame.to_pandas_on_spark is deprecated. Use DataFrame.pandas_api instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "weather_dict = trans_data_6.select(\"Weather\").distinct().to_pandas_on_spark().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transweather(weather: str) -> int:\n",
    "    for key, value in weather_dict[\"Weather\"].items():\n",
    "        if value == weather:\n",
    "            return key\n",
    "udf_weather = functions.udf(transweather, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data_7 = trans_data_6.withColumn(\"num_weather\", udf_weather(functions.col(\"Weather\"))).drop(\"Weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+------------+-----------+\n",
      "|Temp|Wind|Humidity|Barometer|num_signal|num_direct|num_city|   tmp_STD|   tmp_ATD|   tmp_STA|   tmp_ATA|num_duration|num_weather|\n",
      "+----+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+------------+-----------+\n",
      "|  32|  13|      67|     1007|         2|       200|      10|1663057800|1663058760|1663063500|1663063260|          75|         24|\n",
      "|  26|   6|      89|     1008|         2|         0|      10|1662980400|1662981420|1662985200|1662985560|          69|          3|\n",
      "|  29|   6|      79|     1006|         3|         0|      10|1662885000|1662888180|1662890700|1662892560|          73|         24|\n",
      "|  33|   6|      59|     1007|         1|         0|      10|1662712200|1662718020|1662717900|1662722460|          74|         24|\n",
      "|  27|  17|      89|     1007|         2|       260|      10|1662539400|1662541020|1662545100|1662545340|          72|         50|\n",
      "|  32|  19|      59|     1006|         2|       280|      10|1662453000|1662453720|1662458700|1662458160|          74|         24|\n",
      "|  30|  17|      66|     1006|         1|       270|      10|1662280200|1662287220|1662285900|1662291600|          73|         24|\n",
      "|  33|  11|      59|     1004|         3|       270|      10|1662193800|1662196200|1662199500|1662201120|          82|         24|\n",
      "|  28|  11|      89|     1005|         2|       280|      10|1662107400|1662108960|1662113100|1662113760|          80|         44|\n",
      "|  32|   6|      63|     1004|         3|         0|      10|1661934600|1661938860|1661940300|1661942880|          67|         24|\n",
      "|  33|  19|      63|     1006|         1|       150|      10|1661761800|1661765760|1661767500|1661770260|          74|         24|\n",
      "|  32|   4|      63|     1004|         3|         0|      10|1661675400|1661677860|1661681100|1661682420|          75|         44|\n",
      "|  24|  19|      94|     1009|         3|       250|      10|1661502600|1661506020|1661508300|1661510100|          68|         50|\n",
      "|  28|  17|      79|     1006|         2|       220|      10|1661416200|1661418060|1661421900|1661422260|          70|         44|\n",
      "|  33|  11|      59|     1003|         1|       310|      10|1661329800|1661337960|1661335500|1661342280|          72|         24|\n",
      "|  33|  13|      59|     1004|         2|       290|      10|1661243400|1661244480|1661249100|1661248860|          73|         24|\n",
      "|  34|  17|      53|     1004|         1|       280|      10|1661157000|1661168220|1661162700|1661172900|          78|         36|\n",
      "|  29|  19|      70|     1005|         3|       240|      10|1661070600|1661073360|1661076300|1661077500|          70|         24|\n",
      "|  29|  20|      79|     1004|         3|       250|      10|1660984200|1660987920|1660989900|1660992180|          71|         45|\n",
      "|  30|  26|      70|     1004|         1|       250|      10|1660897800|1660900680|1660903500|1660906560|          98|         44|\n",
      "+----+----+--------+---------+----------+----------+--------+----------+----------+----------+----------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_data_7.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cai dat thuat toan</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hong_hai/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3313: FutureWarning: DataFrame.to_pandas_on_spark is deprecated. Use DataFrame.pandas_api instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_df = trans_data_7.select(\"*\").to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_df = _df.sort_values(by=[\"num_direct\",\"num_duration\"])\n",
    "\n",
    "training_df = _df.loc[:80000,:]\n",
    "target_train = training_df[\"num_signal\"]\n",
    "training_data = training_df.drop(columns=\"num_signal\")\n",
    "\n",
    "testing_df = _df.loc[80000:,:]\n",
    "target_test = testing_df.loc[:,\"num_signal\"]\n",
    "testing_data = testing_df.drop(columns=\"num_signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tinhKhoangCach(coor_1, coor_2):\n",
    "    _tong = 0\n",
    "    for i in range(12):\n",
    "        _tong += (coor_2[i] - coor_1[i]) ** 2\n",
    "    _tong =_tong ** (1/2)\n",
    "    return _tong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(coor_1):\n",
    "    k_nearest_value = []\n",
    "    k_nearest_index = []\n",
    "    for i, coor_2 in training_data.iterrows():\n",
    "        temp = tinhKhoangCach(coor_1, coor_2)\n",
    "        if len(k_nearest_value) < 10:\n",
    "            k_nearest_value.append(temp)\n",
    "            k_nearest_index.append(i)\n",
    "        else:\n",
    "            val_max = k_nearest_value[0]\n",
    "            index_max = 0\n",
    "            for k in range(len(k_nearest_value)):\n",
    "                if k_nearest_value[k] > val_max:\n",
    "                    val_max = k_nearest_value[k]\n",
    "                    index_max = k\n",
    "            if k_nearest_value[index_max] > temp:\n",
    "                k_nearest_value[index_max] = temp\n",
    "                k_nearest_index[index_max] = i\n",
    "    red, green, yellow = 0, 0, 0\n",
    "    for m in k_nearest_index:\n",
    "        temp = target_train[m]\n",
    "        if temp == 1:\n",
    "            red += 1\n",
    "        elif temp == 2:\n",
    "            green += 1\n",
    "        else: yellow += 1\n",
    "    if red > green & red > yellow:\n",
    "        return 1\n",
    "    if green > red & green > yellow:\n",
    "        return 2\n",
    "    else: return 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing():\n",
    "    red_green = 0\n",
    "    red_yellow = 0\n",
    "    red_red = 0\n",
    "    green_green = 0\n",
    "    green_red = 0\n",
    "    green_yellow = 0\n",
    "    yellow_green = 0\n",
    "    yellow_red = 0\n",
    "    yellow_yellow = 0\n",
    "\n",
    "    for i, coor in testing_data.iterrows():\n",
    "        result = KNN(coor)\n",
    "        target = target_test[i]\n",
    "        if target == result:\n",
    "            if result == 1:\n",
    "                red_red += 1\n",
    "            elif result == 2:\n",
    "                green_green += 1\n",
    "            else:\n",
    "                yellow_yellow += 1\n",
    "        else:\n",
    "            if target == 1:\n",
    "                if result == 2:\n",
    "                    red_green += 1\n",
    "                else:\n",
    "                    red_yellow += 1\n",
    "            if target == 2:\n",
    "                if result == 1:\n",
    "                    green_red += 1\n",
    "                else:\n",
    "                    green_yellow += 1\n",
    "            else:\n",
    "                if result == 1:\n",
    "                    yellow_red += 1\n",
    "                else:\n",
    "                    yellow_green += 1\n",
    "    print(red_green, red_yellow, red_red, \"\\n\", green_green, green_yellow, green_red, \"\\n\", yellow_green, yellow_yellow, yellow_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testing()\n",
      "Cell \u001b[0;32mIn[103], line 13\u001b[0m, in \u001b[0;36mtesting\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m yellow_yellow \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i, coor \u001b[39min\u001b[39;00m testing_data\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m---> 13\u001b[0m     result \u001b[39m=\u001b[39m KNN(coor)\n\u001b[1;32m     14\u001b[0m     target \u001b[39m=\u001b[39m target_test[i]\n\u001b[1;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m target \u001b[39m==\u001b[39m result:\n",
      "Cell \u001b[0;32mIn[102], line 4\u001b[0m, in \u001b[0;36mKNN\u001b[0;34m(coor_1)\u001b[0m\n\u001b[1;32m      2\u001b[0m k_nearest_value \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m k_nearest_index \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m i, coor_2 \u001b[39min\u001b[39;00m training_data\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m     temp \u001b[39m=\u001b[39m tinhKhoangCach(coor_1, coor_2)\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(k_nearest_value) \u001b[39m<\u001b[39m \u001b[39m10\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/pandas/frame.py:1410\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[39mreturn\u001b[39;00m k, v\n\u001b[1;32m   1407\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(\n\u001b[1;32m   1408\u001b[0m     extract_kv_from_spark_row, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal\u001b[39m.\u001b[39mresolved_copy\u001b[39m.\u001b[39mspark_frame\u001b[39m.\u001b[39mtoLocalIterator()\n\u001b[1;32m   1409\u001b[0m ):\n\u001b[0;32m-> 1410\u001b[0m     s \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mSeries(v, index\u001b[39m=\u001b[39;49mcolumns, name\u001b[39m=\u001b[39;49mk)\n\u001b[1;32m   1411\u001b[0m     \u001b[39myield\u001b[39;00m k, s\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:474\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    472\u001b[0m manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 474\u001b[0m     data \u001b[39m=\u001b[39m SingleBlockManager\u001b[39m.\u001b[39;49mfrom_array(data, index)\n\u001b[1;32m    475\u001b[0m \u001b[39melif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    476\u001b[0m     data \u001b[39m=\u001b[39m SingleArrayManager\u001b[39m.\u001b[39mfrom_array(data, index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1936\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1931\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1932\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_array\u001b[39m(\u001b[39mcls\u001b[39m, array: ArrayLike, index: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SingleBlockManager:\n\u001b[1;32m   1933\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1934\u001b[0m \u001b[39m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1936\u001b[0m     block \u001b[39m=\u001b[39m new_block(array, placement\u001b[39m=\u001b[39;49m\u001b[39mslice\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39mlen\u001b[39;49m(index)), ndim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m   1937\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(block, index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:2180\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   2176\u001b[0m     placement \u001b[39m=\u001b[39m BlockPlacement(placement)\n\u001b[1;32m   2178\u001b[0m check_ndim(values, placement, ndim)\n\u001b[0;32m-> 2180\u001b[0m klass \u001b[39m=\u001b[39m get_block_type(values\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m   2182\u001b[0m values \u001b[39m=\u001b[39m maybe_coerce_values(values)\n\u001b[1;32m   2183\u001b[0m \u001b[39mreturn\u001b[39;00m klass(values, ndim\u001b[39m=\u001b[39mndim, placement\u001b[39m=\u001b[39mplacement)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:2148\u001b[0m, in \u001b[0;36mget_block_type\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   2146\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, PeriodDtype):\n\u001b[1;32m   2147\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m NDArrayBackedExtensionBlock\n\u001b[0;32m-> 2148\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(dtype, ExtensionDtype):\n\u001b[1;32m   2149\u001b[0m     \u001b[39m# Note: need to be sure PandasArray is unwrapped before we get here\u001b[39;00m\n\u001b[1;32m   2150\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m ExtensionBlock\n\u001b[1;32m   2152\u001b[0m \u001b[39melif\u001b[39;00m kind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "testing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
